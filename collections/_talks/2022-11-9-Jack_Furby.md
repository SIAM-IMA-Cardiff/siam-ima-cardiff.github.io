---
layout: talk
title: "Can we teach a Concept Bottleneck Model to learn what we want?"
speaker: Jack Furby
---
In a previous talk, I discussed a type of Neural Network called a Concept Bottleneck Model (CBM) which first maps raw input(s) to a vector of human-defined concepts, before using this vector to predict a final classification. With this model we may expect concepts to map to distinct regions of the input but, as shown, that was not the case. Today's talk will be an updated look at CBMs and how we can train the model to work as we intend, with concepts predicted based on the presence or non-presence of them in an input image.


The talk will start with a recap of the previous talk before moving on to our recent developments and ending with a live demo. Knowledge of the previous talk is not required to understand this talk.
